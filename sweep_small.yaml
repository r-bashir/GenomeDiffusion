# Small W&B Sweeps Configuration for Local Testing
# Focus: Key parameters only for quick validation
# Purpose: Verify sweep setup works before running full HPO

program: train_sweep.py
method: bayes
metric:
  goal: minimize
  name: val_loss_epoch

# Early termination
early_terminate:
  type: hyperband
  min_iter: 5
  eta: 2

parameters:
  # === OPTIMIZER ===
  learning_rate:
    values: [1e-4, 3e-4, 5e-4, 1e-3, 3e-3]

  weight_decay:
    values: [1e-5, 1e-4, 1e-3]

  amsgrad:
    values: [true, false]

  # === SCHEDULER ===
  scheduler_type:
    values: ['cosine', 'reduce']

  # === DATA ===
  batch_size:
    values: [16, 32, 64]

  # === TRAINING ===
  epochs:
    value: 20

  # === MODEL / ATTENTION COMPARISON ===
  attention_type:
    values: ["full", "linear", "sparse"]

  # Only applies to sparse; for full/linear it is ignored by the model
  attention_window:
    values: [16, 32, 128, 512]

  num_global_tokens:
    values: [16, 32, 64]

  # Keep heads/dim_head fixed for fairness (override if needed)

  # === DATA SEQ LENGTHS ===
  seq_length:
    values: [100, 1000]

# Small number of runs for testing
# Note: count is specified via --count flag when running the agent
