{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb76e34-e7e2-43cc-a5af-9a242cbc7656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pyarrow\n",
    "import fastparquet\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "\n",
    "# Pytorch Lightening\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# For Visualization\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline     \n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9576363d-9b83-4f06-a0d6-2b74577c7d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "def load_data(input_path=\"\"):\n",
    "\n",
    "    # read data\n",
    "    data = pd.read_parquet(input_path).to_numpy()\n",
    "\n",
    "    # normalize data: map (0 → 0.0, 1 → 0.5, 2 → 1.0)\n",
    "    data = np.where(data == 0, 0.0, data)  # Map 0 to 0.0\n",
    "    data = np.where(data == 1, 0.5, data)  # Map 1 to 0.5\n",
    "    data = np.where(data == 2, 1.0, data)  # Map 2 to 1.0\n",
    "    \n",
    "    return torch.FloatTensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17af7699-f62d-42f4-bf7f-b0890a3fd760",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"HO_data/HO_data_filtered/HumanOrigins2067_filtered.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83718808-8c3b-4558-ab29-44afee202f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_data = load_data(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30f6777c-c42c-4c8b-ba76-247954144348",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([160858, 2067])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snp_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5695fac1-fb3b-4d0f-8b2a-e16d560e8a8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values after normalization: [0.  0.5 1.  9. ]\n"
     ]
    }
   ],
   "source": [
    "# Verification\n",
    "unique_values = np.unique(snp_data)\n",
    "print(\"Unique values after normalization:\", unique_values)  # Should show [0.0, 0.5, 1.0, 9.0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1928d5a8-7025-4859-b232-97d30cf7f799",
   "metadata": {},
   "source": [
    "# Maybe I don't need it:\n",
    "class SNPDataset(Dataset):\n",
    "    def __init__(self, input_path):\n",
    "        self.data = load_data(input_path)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]  # Number of samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]  # Return one sample (row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f581bb64-75cc-4cf9-ac43-e21ad293ebb4",
   "metadata": {},
   "source": [
    "### _LightningDataModule_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b113bb7d-8237-4dec-95e1-dc2426cc2a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNPDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, input_path, batch_size=256, num_workers=1):\n",
    "        super().__init__()\n",
    "        self.path = input_path\n",
    "        self.batch_size = batch_size\n",
    "        self.workers = num_workers\n",
    "        self.data_split = [128686, 16086, 16086] # 80%, 10% and 10%\n",
    "\n",
    "    # Setup Data\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"Prepare the dataset\"\"\"\n",
    "        full_dataset = load_data(self.path)\n",
    "        self.trainset, self.valset, self.testset = random_split(\n",
    "            full_dataset,\n",
    "            self.data_split,\n",
    "            generator=torch.Generator().manual_seed(42)  # Fixed seed for reproducibility\n",
    "        )\n",
    "\n",
    "    # Data Loaders\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.trainset, batch_size=self.batch_size, shuffle=True, num_workers=self.workers\n",
    "            )  # , pin_memory=True, persistent_workers=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.valset, batch_size=self.batch_size, shuffle=False, num_workers=self.workers\n",
    "            )  # , pin_memory=True, persistent_workers=True)\n",
    "        \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.testset, batch_size=self.batch_size, shuffle=False, num_workers=self.workers\n",
    "            )  # , pin_memory=True, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3c06bc6-85fa-4751-b7ab-d825cb1689cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize DataModule\n",
    "snp_data_module = SNPDataModule(input_path=input_file, batch_size=256, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4d3590e-53cd-4785-8f27-aa46c32c0a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Data\n",
    "snp_data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85755e59-5235-4f8c-a11d-5d4d2fa5ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DataLoader\n",
    "train_loader = snp_data_module.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44982907-9fe9-4717-8168-b10134f212be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch from DataLoader\n",
    "sample_batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eff3f5bd-c13a-4132-b1bd-bd13164c24c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Shape: torch.Size([256, 2067])\n",
      "First 5 Samples:\n",
      " tensor([[0.0000, 0.0000, 0.0000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.5000, 1.0000],\n",
      "        [0.5000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 1.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Batch Shape:\", sample_batch.shape)  # Expected: (batch_size, num_markers)\n",
    "print(\"First 5 Samples:\\n\", sample_batch[:5])  # Show first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01e138a-0332-49c7-a841-38c7cb8d2a7c",
   "metadata": {},
   "source": [
    "## _Test Model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5242018-1743-4429-b450-8f7310077be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import DDPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15d396ef-bad3-4371-a820-70ae64a58aeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (512x1 and 32x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m ddpm \u001b[38;5;241m=\u001b[39m DDPM(snp_length\u001b[38;5;241m=\u001b[39mnum_snps)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Generate synthetic SNP samples\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m generated_snps \u001b[38;5;241m=\u001b[39m \u001b[43mddpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnp_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_snps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(generated_snps\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Expected output: [batch_size, 1, num_snps]\u001b[39;00m\n",
      "File \u001b[0;32m~/Semester/Thesis/GenomeDiffusion/model.py:130\u001b[0m, in \u001b[0;36mDDPM.sample\u001b[0;34m(self, batch_size, snp_length, device)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps)):\n\u001b[1;32m    129\u001b[0m     t_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((batch_size,), t, device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m--> 130\u001b[0m     predicted_noise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     alpha_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha[t]\n\u001b[1;32m    133\u001b[0m     alpha_cumprod_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_cumprod[t]\n",
      "File \u001b[0;32m~/Semester/Thesis/GenomeDiffusion/model.py:120\u001b[0m, in \u001b[0;36mDDPM.forward\u001b[0;34m(self, x_noisy, t)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03mx_noisy: Noisy SNP data [batch_size, 1, num_snps]\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03mt: Time step tensor [batch_size]\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m t_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_embedding(t)  \u001b[38;5;66;03m# Get sinusoidal embeddings\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_noisy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_emb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Pydiff/lib/python3.13/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Pydiff/lib/python3.13/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Semester/Thesis/GenomeDiffusion/model.py:87\u001b[0m, in \u001b[0;36mUNet1D.forward\u001b[0;34m(self, x, t_emb)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t_emb):\n\u001b[1;32m     83\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    x: Noisy SNP data of shape [batch_size, 1, num_snps]\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    t_emb: Time embeddings of shape [batch_size, time_emb_dim]\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m     t_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_emb\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Expand for broadcasting in 1D convs\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     x, skip1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown1(x \u001b[38;5;241m+\u001b[39m t_emb)\n\u001b[1;32m     90\u001b[0m     x, skip2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown2(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/Pydiff/lib/python3.13/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Pydiff/lib/python3.13/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/Pydiff/lib/python3.13/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (512x1 and 32x32)"
     ]
    }
   ],
   "source": [
    "# Example data\n",
    "batch_size = 16\n",
    "num_snps = 2067\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Initialize model\n",
    "ddpm = DDPM(snp_length=num_snps).to(device)\n",
    "\n",
    "# Generate synthetic SNP samples\n",
    "generated_snps = ddpm.sample(batch_size=batch_size, snp_length=num_snps, device=device)\n",
    "print(generated_snps.shape)  # Expected output: [batch_size, 1, num_snps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308140bd-3c4b-44ee-9a06-7623ed9a55d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d0ff3b-c011-4b3c-8083-d7842d73f314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc08923-21d4-4986-b5c3-3185259fb664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f5816-ae2d-4f24-82cc-988b1611fb8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a839084-3720-4916-82ae-c6af0b7e86a1",
   "metadata": {},
   "source": [
    "### _LightningModule_\n",
    "\n",
    "- Model\n",
    "- Training Hooks (training, validation, testing)\n",
    "- Data Hooks (training, validation, testing)\n",
    "- etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450663c2-fd77-4d60-95fc-da3e93d09cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkBase(pl.LightningModule):\n",
    "    def __init__(self, input_path, hparams):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.path = hparams[\"input_path\"]\n",
    "        self.split = [10, 1, 1]\n",
    "        self.batch = 64\n",
    "        self.workers = 4\n",
    "        self.data_split = [128686, 16086, 16086] # 80%, 10% and 10%\n",
    "        self.trainset, self.valset, self.testset = None, None, None\n",
    "        \n",
    "        # Save hyperparameters\n",
    "        self.save_hyperparameters(hparams)\n",
    "\n",
    "    # Setup Data\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"Prepare the dataset\"\"\"\n",
    "        full_dataset = load_data(self.path)\n",
    "        self.trainset, self.valset, self.testset = random_split(\n",
    "            full_dataset,\n",
    "            self.data_split,\n",
    "            generator=torch.Generator().manual_seed(42)  # Fixed seed for reproducibility\n",
    "        )\n",
    "\n",
    "    # Data Loaders\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.trainset, batch_size=self.batch_size, shuffle=True, num_workers=self.workers\n",
    "            )  # , pin_memory=True, persistent_workers=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.valset, batch_size=self.batch_size, shuffle=False, num_workers=self.workers\n",
    "            )  # , pin_memory=True, persistent_workers=True)\n",
    "        \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.testset, batch_size=self.batch_size, shuffle=False, num_workers=self.workers\n",
    "            )  # , pin_memory=True, persistent_workers=True)\n",
    "\n",
    "    # Configure Optimizer & Scheduler\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure the Optimizer and Scheduler\"\"\"\n",
    "        optimizer = [\n",
    "            torch.optim.AdamW(\n",
    "                self.parameters(),\n",
    "                lr=(self.hparams[\"lr\"]),\n",
    "                betas=(0.9, 0.999),\n",
    "                eps=1e-08,\n",
    "                amsgrad=True,\n",
    "            )\n",
    "        ]\n",
    "        scheduler = [\n",
    "            {\n",
    "                \"scheduler\": torch.optim.lr_scheduler.StepLR(\n",
    "                    optimizer[0],\n",
    "                    step_size=0.3,\n",
    "                    gamma=10,\n",
    "                ),\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            }\n",
    "        ]\n",
    "        return optimizer, scheduler\n",
    "    \n",
    "    # Trainig Step\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # YOUR CODE HERE:\n",
    "        pass\n",
    "\n",
    "    # Validation Step\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # YOUR CODE HERE:\n",
    "        pass\n",
    "\n",
    "    # Test Step\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # YOUR CODE HERE:\n",
    "        pass\n",
    "\n",
    "    # Optimizer Step\n",
    "    def on_before_optimizer_step(self, optimizer, *args, **kwargs):\n",
    "        \"\"\"Settings before Optimizer Step\"\"\"\n",
    "\n",
    "        # warm up lr\n",
    "        if self.hparams.get(\"warmup\", 0) and (\n",
    "            self.trainer.current_epoch < self.hparams[\"warmup\"]\n",
    "        ):\n",
    "            lr_scale = min(\n",
    "                1.0, float(self.trainer.current_epoch + 1) / self.hparams[\"warmup\"]\n",
    "            )\n",
    "            for pg in optimizer.param_groups:\n",
    "                pg[\"lr\"] = lr_scale * self.hparams[\"lr\"]\n",
    "\n",
    "        # after reaching minimum learning rate, stop LR decay\n",
    "        for pg in optimizer.param_groups:\n",
    "            pg[\"lr\"] = max(pg[\"lr\"], self.hparams.get(\"min_lr\", 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6037117e-e192-4ab2-b0c4-6a290265ac45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aeb21f-efe4-474a-9690-9be72fc5397c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dd9f11-f440-4fa6-afd2-12ca75ce0b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb70729-7709-46f0-b688-2f9efd817287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46eb6ad-78f5-47bc-a964-1593fbd96a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c050d2c5-0e45-4130-8647-67b15615389c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29840246-72f5-473d-8cfe-47c74e5da428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ddd81b5-ac91-4a6f-a468-0d691a68b93e",
   "metadata": {},
   "source": [
    "### _Model Development_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf89b9-6328-47af-9207-646b5b265833",
   "metadata": {},
   "source": [
    "- These define the range of noise levels.\n",
    "- The noise increases from 1e-4 (almost no noise) to 0.02 (more noise) over time.\n",
    "- `t_range` → Total number of diffusion steps.\n",
    "- `in_size` → Input image size (flattened).\n",
    "- `img_depth` → Number of image channels (e.g., 3 for RGB).\n",
    "- `self.unet` → A U-Net model that predicts the noise at each step.\n",
    "- Simply passes the input image (x) and time step (t) to the `U-Net`.\n",
    "- The `U-Net` predicts the noise (ϵ) at that time step.\n",
    "- `Beta function` Linearly interpolates between beta_small and beta_large over time, Controls how much noise is added at each time step.\n",
    "- `α-alpha function` controls signal preservation. Since β(t) is noise, α(t) = 1 - β(t) represents how much of the original image remains at each step.\n",
    "- `α̅(t)-Cumulative alpha` is the product of all previous α(t) values.Represents the total preservation of the original image after t steps.\n",
    "- `Get_loss` Selects a random diffusion step t for each image in the batch. Generates Gaussian noise ϵ for each image.\n",
    "- Loop: Computes the noisy version of the image using First term: Preserves part of the original image. Second term: Adds noise.\n",
    "- Denoising and Loss calculation: Runs noisy images through the U-Net to predict the noise (e_hat). Loss function: Mean Squared Error (MSE) between: Predicted noise (e_hat) Actual noise (ϵ) This teaches the model to predict noise correctly, enabling image denoising.\n",
    "- `Denoise_sample` Starts from a noisy sample (x_T = pure noise).Generates random Gaussian noise (z) unless it’s the last step.\n",
    "- Gets predicted noise (e_hat) from U-Net. Computes the denoised image (x_{t-1}) using:\n",
    "First term: Restores signal.\n",
    "Second term: Removes predicted noise.\n",
    "Third term: Adds slight randomness (for realistic diversity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a5c9f4-c6d1-4372-84c0-0d614a575128",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel(NetworkBase):\n",
    "    def __init__(self, in_size, t_range, img_depth):\n",
    "        super().__init__()\n",
    "        self.beta_small = 1e-4\n",
    "        self.beta_large = 0.02\n",
    "        self.t_range = t_range\n",
    "        self.in_size = in_size\n",
    "\n",
    "        self.unet = Unet(dim = 64, dim_mults = (1, 2, 4, 8), channels=img_depth)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        return self.unet(x, t)\n",
    "\n",
    "    def beta(self, t):\n",
    "        # Just a simple linear interpolation between beta_small and beta_large based on t\n",
    "        return self.beta_small + (t / self.t_range) * (self.beta_large - self.beta_small)\n",
    "\n",
    "    def alpha(self, t):\n",
    "        return 1 - self.beta(t)\n",
    "\n",
    "    def alpha_bar(self, t):\n",
    "        # Product of alphas from 0 to t\n",
    "        return math.prod([self.alpha(j) for j in range(t)])\n",
    "\n",
    "    def get_loss(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Corresponds to Algorithm 1 from (Ho et al., 2020).\n",
    "        \"\"\"\n",
    "        # Get a random time step for each image in the batch\n",
    "        ts = torch.randint(0, self.t_range, [batch.shape[0]], device=self.device)\n",
    "        noise_imgs = []\n",
    "        # Generate noise, one for each image in the batch\n",
    "        epsilons = torch.randn(batch.shape, device=self.device)\n",
    "        for i in range(len(ts)):\n",
    "            a_hat = self.alpha_bar(ts[i])\n",
    "            noise_imgs.append(\n",
    "                (math.sqrt(a_hat) * batch[i]) + (math.sqrt(1 - a_hat) * epsilons[i])\n",
    "            )\n",
    "        noise_imgs = torch.stack(noise_imgs, dim=0)\n",
    "        # Run the noisy images through the U-Net, to get the predicted noise\n",
    "        e_hat = self.forward(noise_imgs, ts)\n",
    "        # Calculate the loss, that is, the MSE between the predicted noise and the actual noise\n",
    "        loss = nn.functional.mse_loss(\n",
    "            e_hat.reshape(-1, self.in_size), epsilons.reshape(-1, self.in_size)\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def denoise_sample(self, x, t):\n",
    "        \"\"\"\n",
    "        Corresponds to the inner loop of Algorithm 2 from (Ho et al., 2020).\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            if t > 1:\n",
    "                z = torch.randn(x.shape)\n",
    "            else:\n",
    "                z = 0\n",
    "            # Get the predicted noise from the U-Net\n",
    "            e_hat = self.forward(x, t.view(1).repeat(x.shape[0]))\n",
    "            # Perform the denoising step to take the image from t to t-1\n",
    "            pre_scale = 1 / math.sqrt(self.alpha(t))\n",
    "            e_scale = (1 - self.alpha(t)) / math.sqrt(1 - self.alpha_bar(t))\n",
    "            post_sigma = math.sqrt(self.beta(t)) * z\n",
    "            x = pre_scale * (x - e_scale * e_hat) + post_sigma\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4db2835-e1f4-45cf-bab8-cb5746bb2e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "# my_model = DiffusionMode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea6a9d9-8113-4e29-9146-54f3083d7265",
   "metadata": {},
   "source": [
    "- `dim`: Initial dimension size for the filters in the U-Net.\n",
    "- `dim_mults`: A tuple representing how the dimensions of the feature maps increase during the downsampling and upsampling.\n",
    "- `channels:` The number of input channels (4 for one-hot encoded SNPs: A, C, G, T).\n",
    "- `prev_dim:` Starts as the number of channels (4 for one-hot encoding) and gets updated as we add layers.\n",
    "- `Downsampling layers:` For each value in dim_mults, we create a 1D convolutional layer (nn.Conv1d) that increases the depth of the feature maps.prev_dim keeps track of the number of channels from the previous layer. kernel_size=3 and padding=1 keep the sequence length intact during convolutions (3x3 kernels).\n",
    "- `Upsampling layers:` This part creates the decoder, where we reduce the depth of the feature maps and aim to recreate the input SNP sequence.\n",
    "- `Reversed dim_mults:` Since we are upsampling, we reverse the order of dim_mults.\n",
    "- Final layer: A 1D convolution to reduce the output back to the number of classes (4), i.e., the SNP categories (A, C, G, T).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a22e115-5570-476b-9b0c-0db2e2129d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    \"\"\" Simple U-Net for SNP denoising. \"\"\"\n",
    "    def __init__(self, dim=64, dim_mults=(0, 0.5, 1, 9), channels=4):\n",
    "        super().__init__()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "        \n",
    "        prev_dim = channels\n",
    "        for mult in dim_mults:\n",
    "            self.downs.append(nn.Conv1d(prev_dim, dim * mult, kernel_size=3, padding=1))\n",
    "            prev_dim = dim * mult\n",
    "        \n",
    "        for mult in reversed(dim_mults):\n",
    "            self.ups.append(nn.Conv1d(prev_dim, dim * mult, kernel_size=3, padding=1))\n",
    "            prev_dim = dim * mult\n",
    "        \n",
    "        self.final = nn.Conv1d(prev_dim, channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        skips = []\n",
    "        for down in self.downs:\n",
    "            x = F.relu(down(x))\n",
    "            skips.append(x)\n",
    "\n",
    "        for up in self.ups:\n",
    "            x = F.relu(up(x + skips.pop()))  # Skip connections\n",
    "\n",
    "        return self.final(x)  # Output logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e18946-c142-4d0f-b62d-60cef8a322bd",
   "metadata": {},
   "source": [
    "- `snp_length:` Length of the SNP sequence.\n",
    "- `t_range:` The number of timesteps used for the diffusion process.\n",
    "- `num_classes:` Number of possible categories for each SNP (A, C, G, T).\n",
    "- `beta_small and beta_large:` Parameters that control the amount of noise added at each timestep in the diffusion process.\n",
    "- `Noise schedule:` The beta(t) function defines the noise level at each timestep. It linearly interpolates between beta_small and beta_large over the range of t.\n",
    "- `q_sample(x, t):` Adds noise to the input SNP sequence x at timestep t.\n",
    "- `(1 - beta_t) * x` keeps the original SNP with probability (1 - beta_t).\n",
    "- `(beta_t / self.num_classes)` represents the small probability of flipping the SNP to any of the other categories (A, C, G, T).\n",
    "- `torch.multinomial(probs.view(-1, self.num_classes), 1):` Samples new SNPs based on the probabilities.\n",
    "- `Forward pass:` The noisy SNP data x is passed through the U-Net to get predicted categorical probabilities.\n",
    "- `get_loss():` Computes the loss function for training. It calculates the categorical cross-entropy between the predicted SNP sequence and the ground truth.\n",
    "- `ts:` Randomly generates timesteps for each sample in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65d20eb-a1fc-4bd5-bda7-d9ab26ef1c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, snp_length, t_range):\n",
    "        super().__init__()\n",
    "        self.snp_length = snp_length\n",
    "        self.t_range = t_range\n",
    "        self.beta_small = 1e-4\n",
    "        self.beta_large = 0.02\n",
    "\n",
    "        # Define U-Net (assuming 1 input channel for SNPs)\n",
    "        self.unet = Unet(dim=64, dim_mults=(1, 2, 4, 8), channels=1)  \n",
    "\n",
    "    def beta(self, t):\n",
    "        \"\"\" Defines the noise schedule: a simple linear interpolation. \"\"\"\n",
    "        return self.beta_small + (t / self.t_range) * (self.beta_large - self.beta_small)\n",
    "\n",
    "    def q_sample(self, x, t):\n",
    "        \"\"\"\n",
    "        Forward diffusion process: Adds noise to SNP data.\n",
    "        x: SNP data (normalized, continuous)\n",
    "        t: Time step\n",
    "        \"\"\"\n",
    "        beta_t = self.beta(t)  # Get noise level at time t\n",
    "\n",
    "        # Apply Gaussian noise (since SNPs are normalized as continuous values)\n",
    "        noise = torch.randn_like(x) * math.sqrt(beta_t)\n",
    "\n",
    "        x_t = x + noise  # Add noise to SNP data\n",
    "\n",
    "        # Clip values to stay within valid SNP range\n",
    "        return torch.clamp(x_t, 0.0, 1.0)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        \"\"\" Predicts the noise added to SNPs. \"\"\"\n",
    "        return self.unet(x, t)\n",
    "\n",
    "    def get_loss(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Training loss using Mean Squared Error (MSE).\n",
    "        \"\"\"\n",
    "        ts = torch.randint(0, self.t_range, [batch.shape[0]], device=batch.device)\n",
    "\n",
    "        # Apply Gaussian noise\n",
    "        noisy_batch = torch.stack([self.q_sample(batch[i], ts[i]) for i in range(len(ts))])\n",
    "\n",
    "        # Run noisy SNPs through the model to predict the noise\n",
    "        e_hat = self.forward(noisy_batch, ts)\n",
    "\n",
    "        # Compute MSE loss between predicted noise and actual noise\n",
    "        loss = nn.MSELoss()(e_hat, noisy_batch - batch)  \n",
    "        return loss\n",
    "\n",
    "    def denoise_sample(self, x, t):\n",
    "        \"\"\"\n",
    "        Reverse diffusion: Recovers the SNPs step-by-step.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Predict the noise\n",
    "            e_hat = self.forward(x, t.view(1).repeat(x.shape[0]))\n",
    "\n",
    "            # Perform the denoising step: x_(t-1) = x_t - predicted_noise\n",
    "            x_t_minus_1 = x - e_hat\n",
    "\n",
    "            # Clip values to stay within valid SNP range\n",
    "            return torch.clamp(x_t_minus_1, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d789dd0d-6992-4565-9f35-afa5b79f078a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981a127d-0c95-4df4-a974-02e792c903b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "class SinusoidalTimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim, max_period=10000):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.max_period = max_period\n",
    "\n",
    "    def forward(self, timesteps):\n",
    "        half_dim = self.dim // 2\n",
    "        freqs = torch.exp(\n",
    "            -math.log(self.max_period) * torch.arange(half_dim, dtype=torch.float32) / half_dim\n",
    "        ).to(timesteps.device)\n",
    "        args = timesteps[:, None].float() * freqs[None]\n",
    "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "        if self.dim % 2:\n",
    "            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
    "        return embedding\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, dim)\n",
    "        self.time_fc = nn.Linear(dim, dim)\n",
    "        self.fc2 = nn.Linear(dim, dim)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, time_emb):\n",
    "        residual = x\n",
    "        x = self.fc1(x)\n",
    "        x += self.time_fc(time_emb)  # Time conditioning\n",
    "        x = self.activation(x)\n",
    "        x = self.fc2(x)\n",
    "        x += residual  # Residual connection\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, snp_length, t_range, time_emb_dim=256):\n",
    "        super().__init__()\n",
    "        self.snp_length = snp_length\n",
    "        self.t_range = t_range\n",
    "        self.beta_small = 1e-4\n",
    "        self.beta_large = 0.02\n",
    "        self.time_emb_dim = time_emb_dim\n",
    "\n",
    "        # Time embedding layer\n",
    "        self.time_embedding = SinusoidalTimeEmbedding(time_emb_dim)\n",
    "\n",
    "        # Label embedding for 3 classes (super-populations)\n",
    "        self.label_embedding = nn.Embedding(3, 3)\n",
    "\n",
    "        # Predictor network\n",
    "        self.input_layer = nn.Linear(snp_length + 3, 256)\n",
    "        self.res_block1 = ResidualBlock(256)\n",
    "        self.res_block2 = ResidualBlock(256)\n",
    "        self.output_layer = nn.Linear(256, snp_length)\n",
    "\n",
    "    def beta(self, t):\n",
    "        \"\"\" Defines the noise schedule: a simple linear interpolation. \"\"\"\n",
    "        return self.beta_small + (t / self.t_range) * (self.beta_large - self.beta_small)\n",
    "\n",
    "    def q_sample(self, x, t):\n",
    "        \"\"\" Forward diffusion process: Adds noise to SNP data. \"\"\"\n",
    "        beta_t = self.beta(t)  # Get noise level at time t\n",
    "        noise = torch.randn_like(x) * math.sqrt(beta_t)\n",
    "        x_t = x + noise  # Add noise to SNP data\n",
    "        return torch.clamp(x_t, 0.0, 1.0)  # Keep within SNP range\n",
    "\n",
    "    def forward(self, x, t, labels):\n",
    "        \"\"\" Predicts the noise added to SNPs. \"\"\"\n",
    "        # Compute sinusoidal time embeddings\n",
    "        time_emb = self.time_embedding(t)\n",
    "\n",
    "        # Compute label embeddings\n",
    "        label_emb = self.label_embedding(labels)\n",
    "\n",
    "        # Concatenate SNP data with label embedding\n",
    "        x = torch.cat([x, label_emb], dim=-1)\n",
    "\n",
    "        # Pass through the predictor network\n",
    "        x = self.input_layer(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.res_block1(x, time_emb)\n",
    "        x = self.res_block2(x, time_emb)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "    def get_loss(self, batch, labels):\n",
    "        \"\"\" Compute MSE loss for training. \"\"\"\n",
    "        ts = torch.randint(0, self.t_range, [batch.shape[0]], device=batch.device)\n",
    "        noisy_batch = torch.stack([self.q_sample(batch[i], ts[i]) for i in range(len(ts))])\n",
    "        e_hat = self.forward(noisy_batch, ts, labels)\n",
    "        loss = nn.MSELoss()(e_hat, noisy_batch - batch)\n",
    "        return loss\n",
    "\n",
    "    def denoise_sample(self, x, t, labels):\n",
    "        \"\"\" Reverse diffusion to recover SNPs. \"\"\"\n",
    "        with torch.no_grad():\n",
    "            time_emb = self.time_embedding(t)\n",
    "            e_hat = self.forward(x, t, labels)\n",
    "            x_t_minus_1 = x - e_hat\n",
    "            return torch.clamp(x_t_minus_1, 0.0, 1.0)  # Keep SNPs in valid range\n",
    "\n",
    "# Optimizer & Learning Rate Scheduler\n",
    "def get_optimizer_and_scheduler(model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=1000)\n",
    "    return optimizer, scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ddf53d-ad1e-41b4-9c49-f02ded1f7616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb1fb8b-abdc-4e22-90f2-d66894446458",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = ... # from LightningDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe05a17-fe23-4a38-a1be-d0ae32ecf212",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ... # instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06647f2d-4e84-4b97-91ed-943eb1e653d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
