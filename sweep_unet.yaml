# ===== W&B Sweeps Configuration for GenomeDiffusion HPO =====
# Comprehensive hyperparameter optimization for cluster/server
# Full hyperparameter search across all important parameters

# Program to run
program: train_sweep.py

# Optimization method
method: bayes

# Total trials across all agents
run_cap: 50

# Metric to optimize
metric:
  goal: minimize
  name: val_loss_epoch

# Early termination
early_terminate:
  type: hyperband
  min_iter: 10  # More aggressive early stopping
  eta: 5  # Faster elimination of poor trials

# Hyperparameter search space
parameters:

  # === DATA ===
  batch_size:
    values: [16, 32, 64]

  # === UNet1D ===
  embedding_dim:
    values: [16, 32, 64, 128]

  dim_mults:
    values: [[1, 2], [1, 2, 4], [1, 2, 4, 8]]

  with_time_emb:
    values: [true, false]

  with_pos_emb:
    values: [true, false]

  edge_pad:
    values: [1, 2, 4]

  norm_groups:
    values: [2, 4, 8, 16]

  # === ATTENTION ===
  use_attention:
    values: [true, false]

  attention_heads:
    values: [4, 8, 16, 32]

  attention_dim_head:
    values: [16, 32, 64, 128]

  # === TRAINING ===
  epochs:
    value: 50

  warmup_epochs:
    values: [5, 10]

  accumulate_grad_batches:
    values: [4, 8, 16]

  # === OPTIMIZER ===
  learning_rate:
    values: [0.0001, 0.0003, 0.0005, 0.001, 0.003, 0.005, 0.01]

  min_lr:
    values: [0.000001, 0.000003, 0.000005, 0.00001]

  weight_decay:
    values: [0.00001, 0.00003, 0.0001, 0.0003, 0.001]

  amsgrad:
    values: [true, false]

  # === SCHEDULER ===
  scheduler_type:
    values: ['cosine', 'reduce']

  eta_min:
    values: [1e-6, 1e-5, 1e-4]

  scheduler_mode:
    values: ['min', 'max']

  scheduler_factor:
    values: [0.3, 0.5, 0.7]

  scheduler_patience:
    values: [5, 10, 15, 20]

  scheduler_threshold:
    values: [1e-6, 1e-5, 1e-4]

  scheduler_min_lr:
    values: [1e-6, 1e-5, 1e-4]
