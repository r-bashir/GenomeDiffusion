{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea0d3c60-c3a9-47fd-a307-acde76f91c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "\n",
    "# Pytorch Lightening\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dd16b9-d156-4499-b63b-4952b46a90a3",
   "metadata": {},
   "source": [
    "## _Time Embedding_\n",
    "- Takes in a batch of scalar time steps and ensures they are 1D.\n",
    "- Computes frequency scales using an exponential decay function.\n",
    "- Generates sinusoidal embeddings by applying sin and cos transformations.\n",
    "- Ensures correct feature dimension by adding padding if necessary.\n",
    "- Returns structured time embeddings that can be used in U-Net-based diffusion models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86484962-0cfb-49b4-a1ab-10fb10840971",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalTimeEmbedding(nn.Module):\n",
    "    \"\"\"Sinusoidal positional embedding (used for time steps in diffusion models).\"\"\"\n",
    "    \n",
    "    def __init__(self, num_features: int):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: Tensor of shape [batch_size] containing scalar time steps.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape [batch_size, num_features], sinusoidal embeddings.\n",
    "        \"\"\"\n",
    "        if inputs.dim() == 2 and inputs.shape[1] == 1:\n",
    "            inputs = inputs.view(-1)  # Flatten if shape is [batch_size, 1]\n",
    "        \n",
    "        device = inputs.device\n",
    "        half_dim = self.num_features // 2\n",
    "        e = math.log(10000.0) / (half_dim - 1)\n",
    "        inv_freq = torch.exp(-e * torch.arange(half_dim, device=device).float())\n",
    "\n",
    "        emb = inputs[:, None] * inv_freq[None, :]\n",
    "        emb = torch.cat([torch.cos(emb), torch.sin(emb)], dim=-1)\n",
    "\n",
    "        if self.num_features % 2 == 1:\n",
    "            emb = nn.functional.pad(emb, (0, 1))  # Pad last dimension if odd\n",
    "\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbf9308-f511-4e8e-b4e5-753bbf8b209f",
   "metadata": {},
   "source": [
    "## _Residual Block_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f376f3-fd98-487f-b18b-ec1a10014447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swish activation function\n",
    "def swish(x):\n",
    "    return x * torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13527e5-0dd0-49a1-b622-8e66def55213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Block with Conv1d\n",
    "class ResBlock1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=kernel_size // 2)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size // 2)\n",
    "        self.residual = nn.Conv1d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else nn.Identity()\n",
    "        self.norm = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.residual(x)\n",
    "        x = F.silu(self.conv1(x))\n",
    "        x = self.norm(self.conv2(x))\n",
    "        return F.silu(x + residual)\n",
    "\n",
    "#  Downsampling Block\n",
    "class DownBlock1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.resblock = ResBlock1D(in_channels, out_channels)\n",
    "        self.downsample = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resblock(x)\n",
    "        return self.downsample(x), x  # Return downsampled + skip connection\n",
    "\n",
    "# Upsampling Block\n",
    "class UpBlock1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.ConvTranspose1d(in_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.resblock = ResBlock1D(out_channels * 2, out_channels)  # Concat skip connection\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, skip], dim=1)  # Concatenate with skip connection\n",
    "        return self.resblock(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f4028-149c-40b3-9aff-957cee30b534",
   "metadata": {},
   "source": [
    "## _U-Net_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149e375c-d88b-45ef-bebf-e5c621463fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#U-Net Model for SNP Data\n",
    "class UNet1D(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, base_channels=32):\n",
    "        super().__init__()\n",
    "        self.down1 = DownBlock1D(in_channels, base_channels)\n",
    "        self.down2 = DownBlock1D(base_channels, base_channels * 2)\n",
    "        self.down3 = DownBlock1D(base_channels * 2, base_channels * 4)\n",
    "\n",
    "        self.mid = ResBlock1D(base_channels * 4, base_channels * 4)\n",
    "\n",
    "        self.up3 = UpBlock1D(base_channels * 4, base_channels * 2)\n",
    "        self.up2 = UpBlock1D(base_channels * 2, base_channels)\n",
    "        self.up1 = UpBlock1D(base_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, skip1 = self.down1(x)\n",
    "        x, skip2 = self.down2(x)\n",
    "        x, skip3 = self.down3(x)\n",
    "\n",
    "        x = self.mid(x)\n",
    "\n",
    "        x = self.up3(x, skip3)\n",
    "        x = self.up2(x, skip2)\n",
    "        x = self.up1(x, skip1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6cd4ea-d337-4701-b712-d925fb714dc5",
   "metadata": {},
   "source": [
    "## _Diffusion Model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e45447f-5ca2-4744-b25a-4b134afc7ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Diffusion Model with DDPM\n",
    "class DDPM(nn.Module):\n",
    "    def __init__(self, snp_length, unet_channels=32, time_emb_dim=32, num_timesteps=1000):\n",
    "        super().__init__()\n",
    "        self.unet = UNet1D(in_channels=1, out_channels=1, base_channels=unet_channels, time_emb_dim=time_emb_dim)\n",
    "        self.time_embedding = SinusoidalTimeEmbedding(time_emb_dim)\n",
    "\n",
    "        # Precompute variance schedule\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.beta = torch.linspace(0.0001, 0.02, num_timesteps)  # Linear schedule\n",
    "        self.alpha = 1.0 - self.beta\n",
    "        self.alpha_cumprod = torch.cumprod(self.alpha, dim=0)\n",
    "\n",
    "    def forward(self, x_noisy, t):\n",
    "        \"\"\"\n",
    "        x_noisy: Noisy SNP data [batch_size, 1, num_snps]\n",
    "        t: Time step tensor [batch_size]\n",
    "        \"\"\"\n",
    "        t_emb = self.time_embedding(t)  # Get sinusoidal embeddings\n",
    "        return self.unet(x_noisy, t_emb)\n",
    "\n",
    "    def sample(self, batch_size, snp_length, device=\"cuda\"):\n",
    "        \"\"\"\n",
    "        Generate SNP samples using DDPM.\n",
    "        \"\"\"\n",
    "        x = torch.randn(batch_size, 1, snp_length, device=device)  # Start from pure noise\n",
    "\n",
    "        for t in reversed(range(self.num_timesteps)):\n",
    "            t_tensor = torch.full((batch_size,), t, device=device, dtype=torch.long)\n",
    "            predicted_noise = self.forward(x, t_tensor)\n",
    "\n",
    "            alpha_t = self.alpha[t]\n",
    "            alpha_cumprod_t = self.alpha_cumprod[t]\n",
    "            beta_t = self.beta[t]\n",
    "\n",
    "            # Reverse diffusion step\n",
    "            mean = (x - beta_t * predicted_noise) / torch.sqrt(alpha_t)\n",
    "            if t > 0:\n",
    "                noise = torch.randn_like(x)  # Add noise except at t=0\n",
    "                x = mean + torch.sqrt(beta_t) * noise\n",
    "            else:\n",
    "                x = mean  # Last step, no noise\n",
    "\n",
    "        return x  # Return denoised SNP sequences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
