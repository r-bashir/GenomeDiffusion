{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea0d3c60-c3a9-47fd-a307-acde76f91c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "\n",
    "# Pytorch Lightening\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e50c425-5240-400a-ba06-07dae5d6773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bcast_right(x: torch.Tensor, ndim: int) -> torch.Tensor:\n",
    "    \"\"\"Util function for broadcasting to the right.\"\"\"\n",
    "    if x.ndim > ndim:\n",
    "        raise ValueError(f'Cannot broadcast a value with {x.ndim} dims to {ndim} dims.')\n",
    "    elif x.ndim < ndim:\n",
    "        difference = ndim - x.ndim\n",
    "        return x.view(x.shape + (1,) * difference)\n",
    "    else:\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dd16b9-d156-4499-b63b-4952b46a90a3",
   "metadata": {},
   "source": [
    "## _Time Embedding_\n",
    "- Takes in a batch of scalar time steps and ensures they are 1D.\n",
    "- Computes frequency scales using an exponential decay function.\n",
    "- Generates sinusoidal embeddings by applying sin and cos transformations.\n",
    "- Ensures correct feature dimension by adding padding if necessary.\n",
    "- Returns structured time embeddings that can be used in U-Net-based diffusion models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86484962-0cfb-49b4-a1ab-10fb10840971",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalTimeEmbedding(nn.Module):\n",
    "    \"\"\"Sinusoidal positional embedding (used for time steps in diffusion models).\"\"\"\n",
    "    \n",
    "    def __init__(self, num_features: int):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: Tensor of shape [batch_size] containing scalar time steps.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape [batch_size, num_features], sinusoidal embeddings.\n",
    "        \"\"\"\n",
    "        if inputs.dim() == 2 and inputs.shape[1] == 1:\n",
    "            inputs = inputs.view(-1)  # Flatten if shape is [batch_size, 1]\n",
    "        \n",
    "        device = inputs.device\n",
    "        half_dim = self.num_features // 2\n",
    "        e = math.log(10000.0) / (half_dim - 1)\n",
    "        inv_freq = torch.exp(-e * torch.arange(half_dim, device=device).float())\n",
    "\n",
    "        emb = inputs[:, None] * inv_freq[None, :]\n",
    "        emb = torch.cat([torch.cos(emb), torch.sin(emb)], dim=-1)\n",
    "\n",
    "        if self.num_features % 2 == 1:\n",
    "            emb = nn.functional.pad(emb, (0, 1))  # Pad last dimension if odd\n",
    "\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd53df4e-872f-4c01-ab7c-76acddb1c0ec",
   "metadata": {},
   "source": [
    "## _Sampling_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d42aa6-fd3d-4c85-8844-0b1f884e1c92",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;21;43;01mUniformDiscreteTimeSampler\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmin\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmax\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tmin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtmin\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m, in \u001b[0;36mUniformDiscreteTimeSampler\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tmin \u001b[38;5;241m=\u001b[39m tmin\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tmax \u001b[38;5;241m=\u001b[39m tmax\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, shape: \u001b[43mSequence\u001b[49m[\u001b[38;5;28mint\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrandint(low\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tmin, high\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tmax, size\u001b[38;5;241m=\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequence' is not defined"
     ]
    }
   ],
   "source": [
    "class UniformDiscreteTimeSampler:\n",
    "\n",
    "    def __init__(self, tmin: int, tmax: int):\n",
    "        self._tmin = tmin\n",
    "        self._tmax = tmax\n",
    "\n",
    "    def sample(self, shape: Sequence[int]) -> torch.Tensor:\n",
    "        return torch.randint(low=self._tmin, high=self._tmax, size=shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbf9308-f511-4e8e-b4e5-753bbf8b209f",
   "metadata": {},
   "source": [
    "## _Residual Block_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a13527e5-0dd0-49a1-b622-8e66def55213",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConv1D(nn.Module):\n",
    "    \"\"\"1D CNN with residual connections for SNP data.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,   # Number of input channels (e.g., 1 if SNPs are single-channel)\n",
    "        out_channels: int,  # Number of output channels (same as in_channels for residual)\n",
    "        kernel_size: int = 3,  # Size of the 1D convolution kernel\n",
    "        activation: str = 'relu'\n",
    "    ):\n",
    "        super(ResidualConv1D, self).__init__()\n",
    "        \n",
    "        self.activation = getattr(F, activation)\n",
    "        padding = kernel_size // 2  # Ensure same spatial size output\n",
    "        \n",
    "        # Convolutional layers with batch normalization\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=padding)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        # Optional embedding for categorical labels (if needed)\n",
    "        self.label_emb = nn.Embedding(3, out_channels)\n",
    "\n",
    "    def forward(self, xt: torch.Tensor, time: torch.Tensor, label: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass with residual connection.\n",
    "        xt: (batch, in_channels, sequence_length)\n",
    "        time: (batch, embedding_dim)\n",
    "        label: (batch,)\n",
    "        \"\"\"\n",
    "        # Label embedding\n",
    "        c = self.label_emb(label).unsqueeze(2)  # (batch, channels) -> (batch, channels, 1)\n",
    "        \n",
    "        # First Conv + BN + Activation\n",
    "        h = self.conv1(xt)  \n",
    "        h = self.bn1(h)\n",
    "        h = self.activation(h)\n",
    "        \n",
    "        # Second Conv + BN\n",
    "        h = self.conv2(h)\n",
    "        h = self.bn2(h)\n",
    "        \n",
    "        # Residual connection\n",
    "        x = xt + h\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f4028-149c-40b3-9aff-957cee30b534",
   "metadata": {},
   "source": [
    "## _U-Net_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efc27ed9-ed5e-421c-9ff7-e7b075e7b772",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataclasses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;129m@dataclasses\u001b[39m\u001b[38;5;241m.\u001b[39mdataclass\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mNetConfig\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     resnet_n_blocks: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      4\u001b[0m     resnet_n_hidden: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataclasses' is not defined"
     ]
    }
   ],
   "source": [
    "@dataclasses.dataclass\n",
    "class NetConfig:\n",
    "    resnet_n_blocks: int = 2\n",
    "    resnet_n_hidden: int = 256\n",
    "    resnet_n_out: int = 6\n",
    "    activation: str = 'elu'\n",
    "    time_embedding_dim: int = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "149e375c-d88b-45ef-bebf-e5c621463fcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NetConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;21;43;01mNet\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModule\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"Combines 1D CNN and time embeddings for SNP data.\"\"\"\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_config\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mNetConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m, in \u001b[0;36mNet\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mNet\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Combines 1D CNN and time embeddings for SNP data.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, net_config: \u001b[43mNetConfig\u001b[49m, name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28msuper\u001b[39m(Net, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_encoder \u001b[38;5;241m=\u001b[39m SinusoidalTimeEmbedding(net_config\u001b[38;5;241m.\u001b[39mtime_embedding_dim)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NetConfig' is not defined"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"Combines 1D CNN and time embeddings for SNP data.\"\"\"\n",
    "    \n",
    "    def __init__(self, net_config: NetConfig, name: str = None):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self._time_encoder = SinusoidalTimeEmbedding(net_config.time_embedding_dim)\n",
    "        \n",
    "        self._predictor = ResidualConv1D(\n",
    "            in_channels=1,  # Assuming SNP data has 1 input channel\n",
    "            out_channels=net_config.resnet_n_hidden,  # Number of hidden channels\n",
    "            kernel_size=3,  # Typical for SNP data\n",
    "            activation=net_config.activation\n",
    "        )\n",
    "\n",
    "    def forward(self, noisy_data: torch.Tensor, time: torch.Tensor, label: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for SNP data.\n",
    "\n",
    "        Args:\n",
    "            noisy_data (torch.Tensor): (batch_size, sequence_length)\n",
    "            time (torch.Tensor): (batch_size,)\n",
    "            label (torch.Tensor): (batch_size,)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: (batch_size, out_channels, sequence_length)\n",
    "        \"\"\"\n",
    "        # Reshape input for Conv1D: (batch_size, 1, sequence_length)\n",
    "        noisy_data = noisy_data.unsqueeze(1)\n",
    "\n",
    "        # Encode time\n",
    "        time_embedding = self._time_encoder(time)\n",
    "\n",
    "        # Pass through 1D CNN predictor\n",
    "        outputs = self._predictor(noisy_data, time_embedding, label)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cded82-a4b8-46f4-b99d-dc51b06bb1fa",
   "metadata": {},
   "source": [
    "## _DDPM Process_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3225c9c-ed85-44e2-a1d3-89a965cbd4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteDDPMProcess:\n",
    "    \"\"\"\n",
    "    A Gaussian diffusion process following the DDPM framework:\n",
    "    q(xt|x0) = N(alpha(t) * x0, sigma(t)^2 * I)\n",
    "\n",
    "    Transition from x0 to xt:\n",
    "        xt = alpha(t) * x0 + sigma(t) * eps, where eps ~ N(0, I).\n",
    "\n",
    "    This implementation supports SNP data with 1D convolutional processing.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_diffusion_timesteps: int = 1000,\n",
    "        beta_start: float = 0.0001,\n",
    "        beta_end: float = 0.02,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes the diffusion process.\n",
    "\n",
    "        Args:\n",
    "            num_diffusion_timesteps (int): Number of diffusion steps.\n",
    "            beta_start (float): Initial beta value.\n",
    "            beta_end (float): Final beta value.\n",
    "        \"\"\"\n",
    "        self._num_diffusion_timesteps = num_diffusion_timesteps\n",
    "        self._beta_start = beta_start\n",
    "        self._beta_end = beta_end\n",
    "        self._betas = np.linspace(self._beta_start, self._beta_end, self._num_diffusion_timesteps)\n",
    "\n",
    "        alphas_bar = self._get_alphas_bar()\n",
    "        self._alphas = torch.tensor(np.sqrt(alphas_bar), dtype=torch.float32)\n",
    "        self._sigmas = torch.tensor(np.sqrt(1 - alphas_bar), dtype=torch.float32)\n",
    "\n",
    "    @property\n",
    "    def tmin(self) -> int:\n",
    "        \"\"\"Minimum timestep value.\"\"\"\n",
    "        return 1\n",
    "\n",
    "    @property\n",
    "    def tmax(self) -> int:\n",
    "        \"\"\"Maximum timestep value.\"\"\"\n",
    "        return self._num_diffusion_timesteps\n",
    "\n",
    "    def _get_alphas_bar(self) -> np.ndarray:\n",
    "        \"\"\"Computes cumulative alpha values following the DDPM formula.\"\"\"\n",
    "        alphas_bar = np.cumprod(1.0 - self._betas)\n",
    "\n",
    "        # Append 1 at the beginning for convenient indexing\n",
    "        alphas_bar = np.concatenate(([1.], alphas_bar))\n",
    "\n",
    "        return alphas_bar\n",
    "\n",
    "    def alpha(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Retrieves alpha(t) for the given time indices.\n",
    "\n",
    "        Args:\n",
    "            t (torch.Tensor): Timesteps (batch_size,).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Alpha values corresponding to timesteps.\n",
    "        \"\"\"\n",
    "        return self._alphas[t.long()]\n",
    "\n",
    "    def sigma(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Retrieves sigma(t) for the given time indices.\n",
    "\n",
    "        Args:\n",
    "            t (torch.Tensor): Timesteps (batch_size,).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Sigma values corresponding to timesteps.\n",
    "        \"\"\"\n",
    "        return self._sigmas[t.long()]\n",
    "\n",
    "    def sample(self, x0: torch.Tensor, t: torch.Tensor, eps: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the forward diffusion process q(xt | x0).\n",
    "\n",
    "        Args:\n",
    "            x0 (torch.Tensor): Original clean input (batch_size, seq_len).\n",
    "            t (torch.Tensor): Diffusion timesteps (batch_size,).\n",
    "            eps (torch.Tensor): Gaussian noise (batch_size, seq_len).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Noisy sample xt.\n",
    "        \"\"\"\n",
    "        alpha_t = self.alpha(t).view(-1, 1)  # Ensure proper broadcasting\n",
    "        sigma_t = self.sigma(t).view(-1, 1)\n",
    "\n",
    "        return alpha_t * x0 + sigma_t * eps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6cd4ea-d337-4701-b712-d925fb714dc5",
   "metadata": {},
   "source": [
    "## _Diffusion Model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d81a05a1-8cf0-44d4-886e-90f522d6e0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel(nn.Module):\n",
    "    \"\"\"Diffusion model with 1D Convolutional network for SNP data.\"\"\"\n",
    "\n",
    "    def __init__(self, diffusion_process, time_sampler, net_config, data_shape):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "\n",
    "        self._process = diffusion_process\n",
    "        self._time_sampler = time_sampler\n",
    "        self._net_config = net_config\n",
    "        self._data_shape = data_shape\n",
    "        self.net_fwd = Net(net_config)  # Uses Net with ResidualConv1D\n",
    "\n",
    "    def loss(self, x0: torch.Tensor, label: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Computes MSE between true noise and predicted noise.\n",
    "        The network's goal is to correctly predict noise (eps) from noisy observations.\n",
    "\n",
    "        Args:\n",
    "            x0 (torch.Tensor): Original clean input data (batch_size, seq_len)\n",
    "            label (torch.Tensor): Label tensor (batch_size,)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: MSE loss\n",
    "        \"\"\"\n",
    "        t = self._time_sampler.sample(shape=(x0.shape[0],))  # Sample time\n",
    "\n",
    "        eps = torch.randn_like(x0, device=x0.device)  # Sample noise\n",
    "\n",
    "        xt = self._process.sample(x0, t, eps)  # Corrupt the data\n",
    "\n",
    "        net_outputs = self.net_fwd(xt, t, label)  # Pass through Conv1D model\n",
    "\n",
    "        loss = torch.mean((net_outputs - eps) ** 2)  # Compute MSE loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def loss_per_timesteps(self, x0: torch.Tensor, eps: torch.Tensor, timesteps: torch.Tensor, label: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Computes loss at specific timesteps.\n",
    "\n",
    "        Args:\n",
    "            x0 (torch.Tensor): Original clean input data.\n",
    "            eps (torch.Tensor): Sampled noise.\n",
    "            timesteps (torch.Tensor): Selected timesteps.\n",
    "            label (torch.Tensor): Label tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Loss values for each timestep.\n",
    "        \"\"\"\n",
    "        losses = []\n",
    "        for t in timesteps:\n",
    "            t = int(t.item()) * torch.ones((x0.shape[0],), dtype=torch.int32, device=x0.device)\n",
    "            xt = self._process.sample(x0, t, eps)\n",
    "            net_outputs = self.net_fwd(xt, t, label)\n",
    "            loss = torch.mean((net_outputs - eps) ** 2)\n",
    "            losses.append(loss)\n",
    "        return torch.stack(losses)\n",
    "\n",
    "    def _reverse_process_step(self, xt: torch.Tensor, t: int, label: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Reverse diffusion step to estimate x_{t-1} given x_t.\n",
    "\n",
    "        Args:\n",
    "            xt (torch.Tensor): Noisy input at time t.\n",
    "            t (int): Current timestep.\n",
    "            label (torch.Tensor): Labels for conditioning.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Estimated previous timestep data.\n",
    "        \"\"\"\n",
    "        t = t * torch.ones((xt.shape[0],), dtype=torch.int32, device=xt.device)\n",
    "\n",
    "        eps_pred = self.net_fwd(xt, t, label)  # Predict epsilon\n",
    "\n",
    "        sqrt_a_t = self._process.alpha(t) / self._process.alpha(t - 1)\n",
    "        inv_sqrt_a_t = 1.0 / sqrt_a_t\n",
    "        beta_t = 1.0 - sqrt_a_t ** 2\n",
    "        inv_sigma_t = 1.0 / self._process.sigma(t)\n",
    "\n",
    "        mean = inv_sqrt_a_t * (xt - beta_t * inv_sigma_t * eps_pred)\n",
    "\n",
    "        std = torch.sqrt(beta_t)\n",
    "        z = torch.randn_like(xt)\n",
    "\n",
    "        return mean + std * z\n",
    "\n",
    "    def sample(self, x0, sample_size, label):\n",
    "        \"\"\"\n",
    "        Samples from the learned reverse diffusion process.\n",
    "\n",
    "        Args:\n",
    "            x0 (torch.Tensor): Initial input (not used, only for device reference).\n",
    "            sample_size (int): Number of samples.\n",
    "            label (torch.Tensor): Labels for conditioning.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Generated samples.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn((sample_size,) + self._data_shape, device=x0.device)\n",
    "\n",
    "            for t in range(self._process.tmax, 0, -1):\n",
    "                x = self._reverse_process_step(x, t, label)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe0a695-b8fb-49ed-a69c-299f9836649a",
   "metadata": {},
   "source": [
    "## _Instantiating_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae547f8-5135-4a9d-b528-0e47879a9411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "diffusion_process = DiscreteDDPMProcess(num_diffusion_timesteps=1000)\n",
    "time_sampler = UniformDiscreteTimeSampler(diffusion_process.tmin, diffusion_process.tmax)\n",
    "model = DiffusionModel(diffusion_process, time_sampler, net_config=NetConfig(), data_shape=(6,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
