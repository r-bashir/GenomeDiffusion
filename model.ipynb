{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea0d3c60-c3a9-47fd-a307-acde76f91c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import dataclasses\n",
    "from typing import Sequence\n",
    "import functools\n",
    "from typing import Tuple  # Add this line to import Tuple\n",
    "from torch import optim\n",
    "#import pytorch_warmup as warmup\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "\n",
    "# Pytorch Lightening\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a8c140-8d59-47c4-b7a4-615a5f8148df",
   "metadata": {},
   "source": [
    "### _Diffusion/Noising Process_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86484962-0cfb-49b4-a1ab-10fb10840971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Embedding, Time Sampling and DDPM Process\n",
    "from model import SinusoidalPositionalEmbeddings, UniformDiscreteTimeSampler, DDPMProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0734a7-dd4f-4021-b46b-46a6271d81ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "733f4028-149c-40b3-9aff-957cee30b534",
   "metadata": {},
   "source": [
    "### _U-Net_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f92e94b-8004-4614-a825-9d897e982b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Join, Downsampling, Upsampling, ConvBlock and ResnetBlock\n",
    "from model import Residual, DownsampleConv, UpsampleConv, ConvBlock, ResnetBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1301bf4b-5282-4fc0-b48a-53e87046b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "\n",
    "    \"\"\"Combines 1D CNN and time embeddings for SNP data.\"\"\"\n",
    "\n",
    "    def __init__(self, dim, init_dim=None, out_dim=None, dim_mults=(1, 2, 4, 8), channels=3, with_time_emb=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.channels = channels\n",
    "        init_dim = init_dim or (dim // 3 * 2)\n",
    "        self.init_conv = nn.Conv1d(channels, init_dim, 7, padding=3)\n",
    "        \n",
    "        dims = [init_dim, *[dim * m for m in dim_mults]]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "        \n",
    "        if with_time_emb:\n",
    "            time_dim = dim\n",
    "            self.time_mlp = nn.Sequential(\n",
    "                nn.Linear(dim, time_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(time_dim, time_dim)\n",
    "            )\n",
    "        else:\n",
    "            time_dim = None\n",
    "            self.time_mlp = None\n",
    "        \n",
    "        self.downs = nn.ModuleList([])\n",
    "        self.ups = nn.ModuleList([])\n",
    "        \n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind == (len(in_out) - 1)\n",
    "            self.downs.append(\n",
    "                nn.ModuleList([\n",
    "                    ResnetBlock(dim_in, dim_out, time_emb_dim=time_dim),\n",
    "                    ResnetBlock(dim_out, dim_out, time_emb_dim=time_dim),\n",
    "                    DownsampleConv(dim_out) if not is_last else nn.Identity()\n",
    "                ])\n",
    "            )\n",
    "        \n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = ResnetBlock(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
    "        self.mid_block2 = ResnetBlock(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
    "        \n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
    "            is_last = ind == (len(in_out) - 1)\n",
    "            self.ups.append(\n",
    "                nn.ModuleList([\n",
    "                    ResnetBlock(dim_out * 2, dim_in, time_emb_dim=time_dim),\n",
    "                    ResnetBlock(dim_in, dim_in, time_emb_dim=time_dim),\n",
    "                    UpsampleConv(dim_in) if not is_last else nn.Identity()\n",
    "                ])\n",
    "            )\n",
    "        \n",
    "        out_dim = out_dim or channels\n",
    "        self.final_conv = nn.Sequential(\n",
    "            ResnetBlock(dim, dim),\n",
    "            nn.Conv1d(dim, out_di98m, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, time):\n",
    "        x = self.init_conv(x)\n",
    "        t = self.time_mlp(time) if self.time_mlp else None\n",
    "        h = []\n",
    "        \n",
    "        for block1, block2, downsample in self.downs:\n",
    "            x = block1(x, t)\n",
    "            x = block2(x, t)\n",
    "            h.append(x)\n",
    "            x = downsample(x)\n",
    "        \n",
    "        x = self.mid_block1(x, t)\n",
    "        x = self.mid_block2(x, t)\n",
    "        \n",
    "        for block1, block2, upsample in self.ups:\n",
    "            x = torch.cat((x, h.pop()), dim=1)\n",
    "            x = block1(x, t)\n",
    "            x = block2(x, t)\n",
    "            x = upsample(x)\n",
    "        \n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6cd4ea-d337-4701-b712-d925fb714dc5",
   "metadata": {},
   "source": [
    "## _Final Diffusion Model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d81a05a1-8cf0-44d4-886e-90f522d6e0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel(nn.Module):\n",
    "    \"\"\"Diffusion model with 1D Convolutional network for SNP data.\"\"\"\n",
    "\n",
    "    def __init__(self, diffusion_process, time_sampler, net_config, data_shape):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "        self._process = diffusion_process\n",
    "        self._time_sampler = time_sampler\n",
    "        self._net_config = net_config\n",
    "        self._data_shape = data_shape\n",
    "        self.net_fwd = Net(net_config)  # Uses Net with ResidualConv1D\n",
    "\n",
    "    def loss(self, x0: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Computes MSE between true noise and predicted noise.\n",
    "        The network's goal is to correctly predict noise (eps) from noisy observations.\n",
    "\n",
    "        Args:\n",
    "            x0 (torch.Tensor): Original clean input data (batch_size, seq_len)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: MSE loss\n",
    "        \"\"\"\n",
    "        t = self._time_sampler.sample(shape=(x0.shape[0],))  # Sample time\n",
    "        eps = torch.randn_like(x0, device=x0.device)         # Sample noise\n",
    "        xt = self._process.sample(x0, t, eps)                # Corrupt the data\n",
    "        net_outputs = self.net_fwd(xt, t)             # Pass through Conv1D model\n",
    "        loss = torch.mean((net_outputs - eps) ** 2)          # Compute MSE loss\n",
    "        return loss\n",
    "\n",
    "    def loss_per_timesteps(self, x0: torch.Tensor, eps: torch.Tensor, timesteps: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Computes loss at specific timesteps.\n",
    "\n",
    "        Args:\n",
    "            x0 (torch.Tensor): Original clean input data.\n",
    "            eps (torch.Tensor): Sampled noise.\n",
    "            timesteps (torch.Tensor): Selected timesteps.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Loss values for each timestep.\n",
    "        \"\"\"\n",
    "        losses = []\n",
    "        for t in timesteps:\n",
    "            t = int(t.item()) * torch.ones((x0.shape[0],), dtype=torch.int32, device=x0.device)\n",
    "            xt = self._process.sample(x0, t, eps)\n",
    "            net_outputs = self.net_fwd(xt, t)\n",
    "            loss = torch.mean((net_outputs - eps) ** 2)\n",
    "            losses.append(loss)\n",
    "        return torch.stack(losses)\n",
    "\n",
    "    def _reverse_process_step(self, xt: torch.Tensor, t: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Reverse diffusion step to estimate x_{t-1} given x_t.\n",
    "\n",
    "        Args:\n",
    "            xt (torch.Tensor): Noisy input at time t.\n",
    "            t (int): Current timestep.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Estimated previous timestep data.\n",
    "        \"\"\"\n",
    "        t = t * torch.ones((xt.shape[0],), dtype=torch.int32, device=xt.device)\n",
    "        eps_pred = self.net_fwd(xt, t)  # Predict epsilon\n",
    "        sqrt_a_t = self._process.alpha(t) / self._process.alpha(t - 1)\n",
    "        inv_sqrt_a_t = 1.0 / sqrt_a_t\n",
    "        beta_t = 1.0 - sqrt_a_t ** 2\n",
    "        inv_sigma_t = 1.0 / self._process.sigma(t)\n",
    "        mean = inv_sqrt_a_t * (xt - beta_t * inv_sigma_t * eps_pred)\n",
    "        std = torch.sqrt(beta_t)\n",
    "        z = torch.randn_like(xt)\n",
    "        return mean + std * z\n",
    "\n",
    "\n",
    "    def sample(self, x0, sample_size):\n",
    "        \"\"\"\n",
    "        Samples from the learned reverse diffusion process without conditioning.\n",
    "    \n",
    "        Args:\n",
    "            x0 (torch.Tensor): Initial input (not used, only for device reference).\n",
    "            sample_size (int): Number of samples.\n",
    "    \n",
    "        Returns:\n",
    "            torch.Tensor: Generated samples.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn((sample_size,) + self._data_shape, device=x0.device)\n",
    "            for t in range(self._process.tmax, 0, -1):\n",
    "                x = self._reverse_process_step(x, t)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe0a695-b8fb-49ed-a69c-299f9836649a",
   "metadata": {},
   "source": [
    "## _Instantiating_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae547f8-5135-4a9d-b528-0e47879a9411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "diffusion_process = DiscreteDDPMProcess(num_diffusion_timesteps=1000)\n",
    "time_sampler = UniformDiscreteTimeSampler(diffusion_process.tmin, diffusion_process.tmax)\n",
    "model = DiffusionModel(diffusion_process, time_sampler, net_config=NetConfig(), data_shape=(6,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
