# Input data path
input_path: "data/HO_data_filtered/HumanOrigins2067_filtered.parquet"
output_path: "output"

# Wandb configuration
project_name: "GenomeDiffusion"  # Project name for wandb
wandb_entity: "r-bashir"  # Your wandb username
wandb:
  log_model: True
  tags: ["genomic-data", "diffusion-model"]

# DDPM
diffusion:
  num_diffusion_timesteps: 1000
  beta_start: 0.0001
  beta_end: 0.02

# Time Sampler
time_sampler:
  tmin: 1
  tmax: 1000

# UNet1D
unet:
  embedding_dim: 32
  dim_mults: [1, 2, 4]  # Reduced from [1, 2, 4, 8]
  channels: 1
  with_time_emb: true
  resnet_block_groups: 8

# Dataset
data:
  seq_length: 2067
  batch_size: 256
  num_workers: 4
  split: [0.8, 0.1, 0.1]

# Training
training:
  num_epochs: 100
  gradient_clip_val: 1.0
  save_top_k: 3
  logger: "wandb"
  
  # Memory optimization
  gradient_checkpointing: true  # Enable gradient checkpointing  

  # Training optimization
  grad_accum: 2  # Gradient accumulation steps
  val_check_interval: 0.5  # Validate twice per epoch
  
  # Early stopping
  patience: 10  # Number of epochs to wait for improvement
  test_threshold: 0.1  # Only test if validation loss is below this
  
  # Learning rate warmup
  warmup_epochs: 5  # Number of epochs for learning rate warmup
  
  # Generation settings
  num_samples: 10  # Number of samples to generate

# Optimizer
optimizer:
  name: 'adamw'
  lr: 1.0e-4
  min_lr: 1.0e-6
  weight_decay: 0.01
  betas: [0.9, 0.999]
  eps: 1.0e-8
  amsgrad: true
